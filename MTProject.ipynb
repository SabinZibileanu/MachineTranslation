{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "IC_5DssHzYuR"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_yOzudXamtm"
      },
      "source": [
        "Firstly, we scraped some romani phrases from different websites: wikipedia [here](https://en.wiktionary.org/wiki/Category:Romani_phrasebook) and tumblr [here](https://www.tumblr.com/aj-rromale/4411570949/a-very-random-assortment-of-romani-phrases-and?redirect_to=%2Faj-rromale%2F4411570949%2Fa-very-random-assortment-of-romani-phrases-and&source=blog_view_login_wall) and from glosbe [here](https://glosbe.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "hjDBYQ-cOlL1"
      },
      "outputs": [],
      "source": [
        "class Scraper:\n",
        "  # This scraper will help us gather romani texts from certain websites\n",
        "\n",
        "  def __init__(self):\n",
        "    self.romani_data_output_path = 'romani.txt'\n",
        "    self.romanian_data_output_path = 'romanian.txt'\n",
        "\n",
        "  def wikipedia_scraper(self, url):\n",
        "    request = requests.get(url)\n",
        "    soup = BeautifulSoup(request.text, 'html.parser')\n",
        "    forbidden_pattern_list = [r'<a\\s+href=\"/wiki/[^\"]+:[^\"]+\"', r'<a\\s+href=\"http[^\"]*\"', r'<a\\s+href=\"\\/w\\/index\\.php\\?[^\"]*\"[^>]*>.*?<\\/a>']\n",
        "    references = soup.find_all('a', href = True, attrs = {'class':'', 'span':'', 'accesskey':'', 'data-mw':'', 'dir':'', 'aria-label':''})\n",
        "    romani_phrases_list = [] # This list will help us with checking the duplicates, as this method can store multiple instances of the same phrase\n",
        "\n",
        "    file_writer = open(self.romani_data_output_path, 'a')\n",
        "\n",
        "    for ref in references:\n",
        "      if not any(re.search(pattern, str(ref)) for pattern in forbidden_pattern_list):\n",
        "        if ref.get_text() not in romani_phrases_list:\n",
        "          romani_phrases_list.append(ref.get_text())\n",
        "          file_writer.write(ref.get_text()), file_writer.write('\\n')\n",
        "\n",
        "\n",
        "\n",
        "  def tumblr_scraper(self, url):\n",
        "    request = requests.get(url)\n",
        "    soup = BeautifulSoup(request.text, 'html.parser')\n",
        "    phrases = soup.find_all('p')\n",
        "    auxiliary_phrase_list = [phrase.get_text() for phrase in phrases] # This list helps us store all the phrases from the website\n",
        "\n",
        "    file_writer = open(self.romani_data_output_path, 'a')\n",
        "    \n",
        "    # Now we will only select the romani phrases\n",
        "    for phrase in auxiliary_phrase_list[1:len(auxiliary_phrase_list) - 1]:\n",
        "      romani_phrase = phrase.split('\\n')\n",
        "      file_writer.write(romani_phrase[0]), file_writer.write('\\n')\n",
        "\n",
        "  def glosbe_romani_scraper(self, url):\n",
        "    # This site helps with different dialects of romani, and so we used balkan and carpathian as it provides phrases as examples\n",
        "    # Note: Some samples were added manually due to some problems with scraping\n",
        "\n",
        "    request = requests.get(url)\n",
        "    soup = BeautifulSoup(request.text, 'html.parser')\n",
        "    romanian_phrases = soup.find_all('div', attrs = {'class':'w-1/2 dir-aware-pr-1'})\n",
        "    carpathian_romani_phrases = soup.find_all('div', attrs = {'class':'w-1/2 dir-aware-pl-1'})\n",
        "\n",
        "    file_writer_romanian, file_writer_romani = open(self.romanian_data_output_path, 'a'), open(self.romani_data_output_path, 'a')\n",
        "\n",
        "    for romanian_phrase, romani_phrase in zip(romanian_phrases, carpathian_romani_phrases):\n",
        "      ro_phrase_text, roma_phrase_text = romanian_phrase.get_text().strip(), romani_phrase.get_text().strip()\n",
        "\n",
        "      if ro_phrase_text and roma_phrase_text:\n",
        "        file_writer_romani.write(roma_phrase_text), file_writer_romani.write('\\n')\n",
        "        file_writer_romanian.write(ro_phrase_text), file_writer_romanian.write('\\n')\n",
        "\n",
        "  def get_phrases_from_dictionary(self, path_dict):\n",
        "    # This method gets some samples from a romanian - kalderash romani dictionary that we found online\n",
        "    \n",
        "    dict_file = open(path_dict, 'r')\n",
        "    file_writer_romanian, file_writer_romani = open(self.romanian_data_output_path, 'a'), open(self.romani_data_output_path, 'a')\n",
        "    for sample in dict_file:\n",
        "      phrases = sample.split(':')\n",
        "      romani_phrase, romanian_phrase = phrases[0], phrases[1].strip()\n",
        "      \n",
        "      file_writer_romani.write(romani_phrase), file_writer_romani.write('\\n')\n",
        "      file_writer_romanian.write(romanian_phrase), file_writer_romanian.write('\\n')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
